encoding<-encoding[, !(names(encoding) %in% del.var)]
# include the trialN
encoding$trialN<-seq(1:nrow(encoding))
# save it
write.csv(encoding,
paste0("/users/francesco/PowerFolders/MemLear/2_Analysis_Folder/all_file_encoding/",
substr(p, 5, 6), "_encoding.csv")
)
error= function(e) {print(paste("problem with participant", p))}
})
}
# first, read the encoding file of that participant
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# select only the task trials
encoding<-encoding[is.na(encoding$trial_cond),]
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# check the images in recog (old) that are in encoding
oldimages<-recog[recog$type=="old",]
oldimages$presInEnc<-NA
for (i in 1:nrow(oldimages)){
if(nrow(encoding[encoding$img==oldimages$images[i],])!=0){
oldimages$presInEnc[i]<-1
} else{
oldimages$presInEnc[i]<-0
}
}
# how many images in encoding?
presInEnc<-sum(oldimages$presInEnc)
# now create accuracy
recog$acc<-ifelse(recog$recog_resp.keys==recog$corr_ans, 1,0)
# calculate hit, miss, rej, and FA
recog$recog_type<-NA
for ( i in 1:nrow(recog)){
if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"HIT"
} else if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"Miss"
} else if(recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"CorrRej"
} else if (recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"FA"
}
}
VoI<-c("recog_type")
# wide dataset
wideData<-table(recog[,VoI])
# convert it to a data.frame
wideData<-as.data.frame(rbind(wideData))
# attach present in encoding
wideData$presInEnc<-presInEnc
# create list number
wideData$listN<-(as.numeric(substr(p, 5,6))%%4)+1
# compute percentage HIT
wideData$HITrate<-wideData$HIT/(wideData$HIT+wideData$Miss)
# percentage false alarm
wideData$FArate<-wideData$FA/(wideData$FA+wideData$CorrRej)
# calculate dprime
library(psycho)
indices <- psycho::dprime(wideData$HIT, wideData$FA, wideData$Miss, wideData$CorrRej)
wideData<-cbind(wideData, indices)
# PR
wideData$hitMinFA<-wideData$HITrate-wideData$FArate
# attach accuracy and confidence ratings in the encoding file
encoding$recogAcc<-NA
encoding$confidence<-NA
wideData<-cbind(wideData, indices)
# PR
wideData$hitMinFA<-wideData$HITrate-wideData$FArate
# attach accuracy and confidence ratings in the encoding file
encoding$recogAcc<-NA
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# select only the task trials
encoding<-encoding[is.na(encoding$trial_cond),]
# now select the recognition file
recog<-read.csv(paste0(p, "/", substr(p, 5,6), "_recog.csv"))
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# check the images in recog (old) that are in encoding
oldimages<-recog[recog$type=="old",]
# attach accuracy and confidence ratings in the encoding file
encoding$recogAcc<-NA
encoding$confidence<-NA
for (n in 1:nrow(encoding)){
if (length(recog$acc[recog$images==encoding$img[n]])!=0){
encoding$recogAcc[n]<-recog$acc[recog$images==encoding$img[n]]
encoding$confidence[n]<-recog$conf_resp.keys[recog$images==encoding$img[n]]
}
}
# check hit rate by condition
hitRbyCond<-encoding %>%
group_by(condition)%>%
dplyr::summarise(hitRCond= mean(recogAcc))
wideData$HITrateLearned<-hitRbyCond$hitRCond[1]
wideData$HITrateKnown<-hitRbyCond$hitRCond[2]
# attach to the datasets
longDatarecog<-rbind(longDatarecog, recog)
# create participant for the wide dataset
wideData$participant<-substr(p, 5,6)
recogData<-rbind(recogData, wideData)
# get participants number
setwd("clean_data")
participants<-list.files()
# Initialize a file for the long data
longDatarecog<-vector()
# Initialize a file for the wide data
recogData<-vector()
# delete participant 27
participants<-participants[-which(participants=="sub-27")]
# loop through participants
for (p in participants){
tryCatch({
# first, read the encoding file of that participant
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# select only the task trials
encoding<-encoding[is.na(encoding$trial_cond),]
# now select the recognition file
recog<-read.csv(paste0(p, "/", substr(p, 5,6), "_recog.csv"))
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# check the images in recog (old) that are in encoding
oldimages<-recog[recog$type=="old",]
oldimages$presInEnc<-NA
for (i in 1:nrow(oldimages)){
if(nrow(encoding[encoding$img==oldimages$images[i],])!=0){
oldimages$presInEnc[i]<-1
} else{
oldimages$presInEnc[i]<-0
}
}
# how many images in encoding?
presInEnc<-sum(oldimages$presInEnc)
# now create accuracy
recog$acc<-ifelse(recog$recog_resp.keys==recog$corr_ans, 1,0)
# calculate hit, miss, rej, and FA
recog$recog_type<-NA
for ( i in 1:nrow(recog)){
if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"HIT"
} else if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"Miss"
} else if(recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"CorrRej"
} else if (recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"FA"
}
}
VoI<-c("recog_type")
# wide dataset
wideData<-table(recog[,VoI])
# convert it to a data.frame
wideData<-as.data.frame(rbind(wideData))
# attach present in encoding
wideData$presInEnc<-presInEnc
# create list number
wideData$listN<-(as.numeric(substr(p, 5,6))%%4)+1
# compute percentage HIT
wideData$HITrate<-wideData$HIT/(wideData$HIT+wideData$Miss)
# percentage false alarm
wideData$FArate<-wideData$FA/(wideData$FA+wideData$CorrRej)
# calculate dprime
library(psycho)
indices <- psycho::dprime(wideData$HIT, wideData$FA, wideData$Miss, wideData$CorrRej)
wideData<-cbind(wideData, indices)
# PR
wideData$hitMinFA<-wideData$HITrate-wideData$FArate
# attach accuracy and confidence ratings in the encoding file
encoding$recogAcc<-NA
encoding$confidence<-NA
for (n in 1:nrow(encoding)){
if (length(recog$acc[recog$images==encoding$img[n]])!=0){
encoding$recogAcc[n]<-recog$acc[recog$images==encoding$img[n]]
encoding$confidence[n]<-recog$conf_resp.keys[recog$images==encoding$img[n]]
}
}
# check hit rate by condition
hitRbyCond<-encoding %>%
group_by(condition)%>%
dplyr::summarise(hitRCond= mean(recogAcc))
wideData$HITrateLearned<-hitRbyCond$hitRCond[1]
wideData$HITrateKnown<-hitRbyCond$hitRCond[2]
# attach to the datasets
longDatarecog<-rbind(longDatarecog, recog)
# create participant for the wide dataset
wideData$participant<-substr(p, 5,6)
recogData<-rbind(recogData, wideData)
#####
# now save the file
# first, clean it
del.var<-c("pract_resp.keys", "pract_resp.corr", "pract_resp.rt", "trial_cond",
"myownaccuracyCORR")
# delelte the variavles
encoding<-encoding[, !(names(encoding) %in% del.var)]
# include the trialN
encoding$trialN<-seq(1:nrow(encoding))
# save it
write.csv(encoding,
paste0("/users/francesco/PowerFolders/MemLear/2_Analysis_Folder/all_file_encoding/",
substr(p, 5, 6), "_encoding.csv")
)
error= function(e) {print(paste("problem with participant", p))}
})
}
# get participants number
setwd("clean_data")
participants<-list.files()
# Initialize a file for the long data
longDatarecog<-vector()
# Initialize a file for the wide data
recogData<-vector()
# delete participant 27
participants<-participants[-which(participants=="sub-27")]
# loop through participants
for (p in participants){
tryCatch({
# first, read the encoding file of that participant
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# select only the task trials
encoding<-encoding[is.na(encoding$trial_cond),]
# now select the recognition file
recog<-read.csv(paste0(p, "/", substr(p, 5,6), "_recog.csv"))
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# check the images in recog (old) that are in encoding
oldimages<-recog[recog$type=="old",]
oldimages$presInEnc<-NA
for (i in 1:nrow(oldimages)){
if(nrow(encoding[encoding$img==oldimages$images[i],])!=0){
oldimages$presInEnc[i]<-1
} else{
oldimages$presInEnc[i]<-0
}
}
# how many images in encoding?
presInEnc<-sum(oldimages$presInEnc)
# now create accuracy
recog$acc<-ifelse(recog$recog_resp.keys==recog$corr_ans, 1,0)
# calculate hit, miss, rej, and FA
recog$recog_type<-NA
for ( i in 1:nrow(recog)){
if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"HIT"
} else if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"Miss"
} else if(recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"CorrRej"
} else if (recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"FA"
}
}
VoI<-c("recog_type")
# wide dataset
wideData<-table(recog[,VoI])
# convert it to a data.frame
wideData<-as.data.frame(rbind(wideData))
# attach present in encoding
wideData$presInEnc<-presInEnc
# create list number
wideData$listN<-(as.numeric(substr(p, 5,6))%%4)+1
# compute percentage HIT
wideData$HITrate<-wideData$HIT/(wideData$HIT+wideData$Miss)
# percentage false alarm
wideData$FArate<-wideData$FA/(wideData$FA+wideData$CorrRej)
# calculate dprime
library(psycho)
indices <- psycho::dprime(wideData$HIT, wideData$FA, wideData$Miss, wideData$CorrRej)
wideData<-cbind(wideData, indices)
# PR
wideData$hitMinFA<-wideData$HITrate-wideData$FArate
print("here")
# attach accuracy and confidence ratings in the encoding file
encoding$recogAcc<-NA
encoding$confidence<-NA
for (n in 1:nrow(encoding)){
if (length(recog$acc[recog$images==encoding$img[n]])!=0){
encoding$recogAcc[n]<-recog$acc[recog$images==encoding$img[n]]
encoding$confidence[n]<-recog$conf_resp.keys[recog$images==encoding$img[n]]
}
}
# check hit rate by condition
hitRbyCond<-encoding %>%
group_by(condition)%>%
dplyr::summarise(hitRCond= mean(recogAcc))
wideData$HITrateLearned<-hitRbyCond$hitRCond[1]
wideData$HITrateKnown<-hitRbyCond$hitRCond[2]
# attach to the datasets
longDatarecog<-rbind(longDatarecog, recog)
# create participant for the wide dataset
wideData$participant<-substr(p, 5,6)
recogData<-rbind(recogData, wideData)
#####
# now save the file
# first, clean it
del.var<-c("pract_resp.keys", "pract_resp.corr", "pract_resp.rt", "trial_cond",
"myownaccuracyCORR")
# delelte the variavles
encoding<-encoding[, !(names(encoding) %in% del.var)]
# include the trialN
encoding$trialN<-seq(1:nrow(encoding))
# save it
write.csv(encoding,
paste0("/users/francesco/PowerFolders/MemLear/2_Analysis_Folder/all_file_encoding/",
substr(p, 5, 6), "_encoding.csv")
)
error= function(e) {print(paste("problem with participant", p))}
})
}
# get participants number
setwd("clean_data")
participants<-list.files()
# Initialize a file for the long data
longDatarecog<-vector()
# Initialize a file for the wide data
recogData<-vector()
# delete participant 27
participants<-participants[-which(participants=="sub-27")]
# loop through participants
for (p in participants){
tryCatch({
# first, read the encoding file of that participant
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# select only the task trials
encoding<-encoding[is.na(encoding$trial_cond),]
# now select the recognition file
recog<-read.csv(paste0(p, "/", substr(p, 5,6), "_recog.csv"))
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# check the images in recog (old) that are in encoding
oldimages<-recog[recog$type=="old",]
oldimages$presInEnc<-NA
for (i in 1:nrow(oldimages)){
if(nrow(encoding[encoding$img==oldimages$images[i],])!=0){
oldimages$presInEnc[i]<-1
} else{
oldimages$presInEnc[i]<-0
}
}
# how many images in encoding?
presInEnc<-sum(oldimages$presInEnc)
# now create accuracy
recog$acc<-ifelse(recog$recog_resp.keys==recog$corr_ans, 1,0)
# calculate hit, miss, rej, and FA
recog$recog_type<-NA
for ( i in 1:nrow(recog)){
if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"HIT"
} else if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"Miss"
} else if(recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"CorrRej"
} else if (recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"FA"
}
}
VoI<-c("recog_type")
# wide dataset
wideData<-table(recog[,VoI])
# convert it to a data.frame
wideData<-as.data.frame(rbind(wideData))
# attach present in encoding
wideData$presInEnc<-presInEnc
# create list number
wideData$listN<-(as.numeric(substr(p, 5,6))%%4)+1
# compute percentage HIT
wideData$HITrate<-wideData$HIT/(wideData$HIT+wideData$Miss)
# percentage false alarm
wideData$FArate<-wideData$FA/(wideData$FA+wideData$CorrRej)
# calculate dprime
library(psycho)
indices <- psycho::dprime(wideData$HIT, wideData$FA, wideData$Miss, wideData$CorrRej)
wideData<-cbind(wideData, indices)
# PR
wideData$hitMinFA<-wideData$HITrate-wideData$FArate
print("here")
# attach accuracy and confidence ratings in the encoding file
encoding$recogAcc<-NA
encoding$confidence<-NA
for (n in 1:nrow(encoding)){
if (length(recog$acc[recog$images==encoding$img[n]])!=0){
encoding$recogAcc[n]<-recog$acc[recog$images==encoding$img[n]]
encoding$confidence[n]<-recog$conf_resp.keys[recog$images==encoding$img[n]]
}
}
# check hit rate by condition
hitRbyCond<-encoding %>%
group_by(condition)%>%
dplyr::summarise(hitRCond= mean(recogAcc))
wideData$HITrateLearned<-hitRbyCond$hitRCond[1]
wideData$HITrateKnown<-hitRbyCond$hitRCond[2]
# attach to the datasets
longDatarecog<-rbind(longDatarecog, recog)
# create participant for the wide dataset
wideData$participant<-substr(p, 5,6)
recogData<-rbind(recogData, wideData)
#####
# now save the file
# first, clean it
del.var<-c("pract_resp.keys", "pract_resp.corr", "pract_resp.rt", "trial_cond",
"myownaccuracyCORR")
# delelte the variavles
encoding<-encoding[, !(names(encoding) %in% del.var)]
# include the trialN
encoding$trialN<-seq(1:nrow(encoding))
# save it
write.csv(encoding,
paste0("/home/francesco/PowerFolders/MemLear/2_Analysis_Folder/all_file_encoding/",
substr(p, 5, 6), "_encoding.csv")
)
error= function(e) {print(paste("problem with participant", p))}
})
}
# delete row names from the dataframe
rownames(recogData)<-NULL
#------------------------------------------------------------------------------#
#
# Analyze Data Expra
#
# created: "Wed Jan 19 19:18:16 2022"
#
# Francesco Pupillo, Goethe University Frankfurt
#
#------------------------------------------------------------------------------#
library(data.table)
library(dplyr)
library(lme4)
library(ggplot2)
rm(list=ls())
# puth the path with the data
inPath <- "..."
# clean data files
inPath<-"all_file_encoding"
setwd("2_Analysis_Folder")
getwd()
setwd("/home/francesco/PowerFolders/MemLear/2_Analysis_Folder/")
setwd("2_Analysis_Folder")
# how many subjects?
subjects<-list.files(inPath)
# import the files
inFiles <- list.files(inPath, pattern="*.csv", full.names=TRUE)
data <- rbindlist(lapply(inFiles,fread),fill=TRUE)
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
# exlcude participants due to problems with lists
part.list.exc<-c(12, 13, 21)
# threshold for excluding participants at encoding
thres.encoding<-0.50
# threshold for excluding participants at retrieval
thres.retrieval<-0.50
# in order to have overall perf, let's aggregate without condition
data.agg.all<- data %>%
group_by(participant) %>%
summarise(recog.acc = mean(recogAcc, na.rm=T),
encoding.acc = mean(task_response.corr))
# which participants to exclude according to encoding performance
part.exc.encod<-data.agg.all$participant[data.agg.all$encoding.acc<thres.encoding ]
# which participants to exclude according to retrieval performance
part.exc.retrieval<-data.agg.all$participant[data.agg.all$recog.acc<thres.retrieval ]
excl.all<-unique(c(part.list.exc, part.exc.encod,part.exc.retrieval ))
# exclude
excl<-data[!data$participant %in% excl.all, ]
data %>%
group_by( condition) %>%
summarise(recogMean = mean(recogAcc, na.rm = T))
View(data.agg.all)
View(data.agg)
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
data.agg<-data %>%
group_by(participant, condition, type) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
View(data.agg)
# set working directory
#setwd("/mnt/ee439dea-0b2a-440e-ae87-ac7b6138b02a/2_Analysis_Folder/MemoKid/memokid_ASHS_analysis/")
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
cd<-getwd()
agegroups<-c("1_Preterm-borns","2_Term-borns","3_Adults")
# retrieve a participant to extract names and number of the variables
#sample<-("/home/pupillo/DATA/2_Analysis_Folder/MemoKid/memokid_ASHS_analysis/1_Preterm-borns/hc_highres/sub-12003/ASHS_segmentations/final/")
sample<-("/home/francesco/Desktop/pepe/2_Analysis_Folder/MemoKid/memokid_ASHS_analysis/new_atlas/1_Preterm-borns/hc_highres/sub-12003/ASHS_segmentations/final/")
scantype<-c("left_corr_usegray_volumes","left_heur_volumes","left_raw_volumes","right_corr_usegray_volumes",  "right_heur_volumes","right_raw_volumes")
hcsubfields<- read.table(paste(sample, "sub-12003_left_corr_usegray_volumes.txt", sep=""))[,3]
hcsubfields<-as.character(hcsubfields)
# delete the last letter of the subfield, indicating the side
hcsubfields<-substr(hcsubfields, 1, nchar(hcsubfields)-1)
# create the variable names
names1<-c("subject", "agegroup", "ICV")
# loop through the scantype and the hcsubfields to create the variable names
varname<-NULL
for (t in 1: length(scantype)){
# loop through subfields
for (s in 1: length(hcsubfields)){
names<-paste(scantype[t], hcsubfields[s], sep="_")
varname<-c(varname, names)
}
}
varname<-c(names1, varname)
# get the subjects
subs<-read.table("subsFinal.txt")
