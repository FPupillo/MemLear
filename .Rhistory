setwd("clean_data")
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# loop through participants
for (p in participants){
tryCatch({
# first, read the encoding file of that participant
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# select only the task trials
encoding<-encoding[is.na(encoding$trial_cond),]
# now select the recognition file
recog<-read.csv(paste0(p, "/", substr(p, 5,6), "_recog.csv"))
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# check the images in recog (old) that are in encoding
oldimages<-recog[recog$type=="old",]
oldimages$presInEnc<-NA
for (i in 1:nrow(oldimages)){
if(nrow(encoding[encoding$img==oldimages$images[i],])!=0){
oldimages$presInEnc[i]<-1
} else{
oldimages$presInEnc[i]<-0
}
}
# how many images in encoding?
presInEnc<-sum(oldimages$presInEnc)
# now create accuracy
recog$acc<-ifelse(recog$recog_resp.keys==recog$corr_ans, 1,0)
# calculate hit, miss, rej, and FA
recog$recog_type<-NA
for ( i in 1:nrow(recog)){
if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"HIT"
} else if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"Miss"
} else if(recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"CorrRej"
} else if (recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"FA"
}
}
VoI<-c("recog_type")
# wide dataset
wideData<-table(recog[,VoI])
# convert it to a data.frame
wideData<-as.data.frame(rbind(wideData))
# attach present in encoding
wideData$presInEnc<-presInEnc
# create list number
wideData$listN<-(as.numeric(substr(p, 5,6))%%4)+1
# compute percentage HIT
wideData$HITrate<-wideData$HIT/(wideData$HIT+wideData$Miss)
# percentage false alarm
wideData$FArate<-wideData$FA/(wideData$FA+wideData$CorrRej)
# calculate dprime
library(psycho)
indices <- psycho::dprime(wideData$HIT, wideData$FA, wideData$Miss, wideData$CorrRej)
wideData<-cbind(wideData, indices)
# PR
wideData$hitMinFA<-wideData$HITrate-wideData$FArate
# attach accuracy in the encoding file
encoding$recogAcc<-NA
for (n in 1:nrow(encoding)){
if (length(recog$acc[recog$images==encoding$img[n]])!=0){
encoding$recogAcc[n]<-recog$acc[recog$images==encoding$img[n]]
}
}
# check hit rate by condition
hitRbyCond<-encoding %>%
group_by(condition)%>%
dplyr::summarise(hitRCond= mean(recogAcc))
wideData$HITrateLearned<-hitRbyCond$hitRCond[1]
wideData$HITrateKnown<-hitRbyCond$hitRCond[2]
# attach to the datasets
longDatarecog<-rbind(longDatarecog, recog)
# create participant for the wide dataset
wideData$participant<-substr(p, 5,6)
recogData<-rbind(recogData, wideData)
#####
# now save the file
# first, clean it
del.var<-c("pract_resp.keys", "pract_resp.corr", "pract_resp.rt", "trial_cond",
"myownaccuracyCORR")
# delelte the variavles
encoding<-encoding[, !(names(encoding) %in% del.var)]
# include the trialN
encoding$trialN<-seq(1:nrow(encoding))
# save it
write.csv(encoding,
paste0("/users/francesco/PowerFolders/MemLear/2_Analysis_Folder/all_file_encoding/",
substr(p, 5, 6), "_encoding.csv")
)
error= function(e) {print(paste("problem with participant", p))}
})
}
# get participants number
setwd("clean_data")
participants<-list.files()
# Initialize a file for the long data
longDatarecog<-vector()
# Initialize a file for the wide data
recogData<-vector()
# delete participant 27
participants<-participants[-which(participants=="sub-27")]
# loop through participants
for (p in participants){
tryCatch({
# first, read the encoding file of that participant
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# select only the task trials
encoding<-encoding[is.na(encoding$trial_cond),]
# now select the recognition file
recog<-read.csv(paste0(p, "/", substr(p, 5,6), "_recog.csv"))
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# check the images in recog (old) that are in encoding
oldimages<-recog[recog$type=="old",]
oldimages$presInEnc<-NA
for (i in 1:nrow(oldimages)){
if(nrow(encoding[encoding$img==oldimages$images[i],])!=0){
oldimages$presInEnc[i]<-1
} else{
oldimages$presInEnc[i]<-0
}
}
# how many images in encoding?
presInEnc<-sum(oldimages$presInEnc)
# now create accuracy
recog$acc<-ifelse(recog$recog_resp.keys==recog$corr_ans, 1,0)
# calculate hit, miss, rej, and FA
recog$recog_type<-NA
for ( i in 1:nrow(recog)){
if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"HIT"
} else if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"Miss"
} else if(recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"CorrRej"
} else if (recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"FA"
}
}
VoI<-c("recog_type")
# wide dataset
wideData<-table(recog[,VoI])
# convert it to a data.frame
wideData<-as.data.frame(rbind(wideData))
# attach present in encoding
wideData$presInEnc<-presInEnc
# create list number
wideData$listN<-(as.numeric(substr(p, 5,6))%%4)+1
# compute percentage HIT
wideData$HITrate<-wideData$HIT/(wideData$HIT+wideData$Miss)
# percentage false alarm
wideData$FArate<-wideData$FA/(wideData$FA+wideData$CorrRej)
# calculate dprime
library(psycho)
indices <- psycho::dprime(wideData$HIT, wideData$FA, wideData$Miss, wideData$CorrRej)
wideData<-cbind(wideData, indices)
# PR
wideData$hitMinFA<-wideData$HITrate-wideData$FArate
# attach accuracy in the encoding file
encoding$recogAcc<-NA
for (n in 1:nrow(encoding)){
if (length(recog$acc[recog$images==encoding$img[n]])!=0){
encoding$recogAcc[n]<-recog$acc[recog$images==encoding$img[n]]
}
}
# check hit rate by condition
hitRbyCond<-encoding %>%
group_by(condition)%>%
dplyr::summarise(hitRCond= mean(recogAcc))
wideData$HITrateLearned<-hitRbyCond$hitRCond[1]
wideData$HITrateKnown<-hitRbyCond$hitRCond[2]
# attach to the datasets
longDatarecog<-rbind(longDatarecog, recog)
# create participant for the wide dataset
wideData$participant<-substr(p, 5,6)
recogData<-rbind(recogData, wideData)
#####
# now save the file
# first, clean it
del.var<-c("pract_resp.keys", "pract_resp.corr", "pract_resp.rt", "trial_cond",
"myownaccuracyCORR")
# delelte the variavles
encoding<-encoding[, !(names(encoding) %in% del.var)]
# include the trialN
encoding$trialN<-seq(1:nrow(encoding))
# save it
write.csv(encoding,
paste0("/users/francesco/PowerFolders/MemLear/2_Analysis_Folder/all_file_encoding/",
substr(p, 5, 6), "_encoding.csv")
)
error= function(e) {print(paste("problem with participant", p))}
})
}
encoding<-read.csv(paste0(p, "/", substr(p, 5,6), "_encoding.csv"))
# select only the task trials
encoding<-encoding[is.na(encoding$trial_cond),]
# now select the recognition file
recog<-read.csv(paste0(p, "/", substr(p, 5,6), "_recog.csv"))
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
paste0(p, "/", substr(p, 5,6), "_recog.csv")
recog<-read.csv(paste0(p, "/", substr(p, 5,6), "_recog.csv"))
# convert the facotrs into characters
encoding$img<-as.character(encoding$img)
recog$images<-as.character(recog$images)
# check the images in recog (old) that are in encoding
oldimages<-recog[recog$type=="old",]
oldimages$presInEnc<-NA
for (i in 1:nrow(oldimages)){
if(nrow(encoding[encoding$img==oldimages$images[i],])!=0){
oldimages$presInEnc[i]<-1
} else{
oldimages$presInEnc[i]<-0
}
}
# how many images in encoding?
presInEnc<-sum(oldimages$presInEnc)
# now create accuracy
recog$acc<-ifelse(recog$recog_resp.keys==recog$corr_ans, 1,0)
# calculate hit, miss, rej, and FA
recog$recog_type<-NA
for ( i in 1:nrow(recog)){
if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"HIT"
} else if (recog$corr_ans[i]=="left"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"Miss"
} else if(recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="right" ){
recog$recog_type[i]<-"CorrRej"
} else if (recog$corr_ans[i]=="right"& recog$recog_resp.keys[i]=="left" ){
recog$recog_type[i]<-"FA"
}
}
VoI<-c("recog_type")
# wide dataset
wideData<-table(recog[,VoI])
# convert it to a data.frame
wideData<-as.data.frame(rbind(wideData))
# attach present in encoding
wideData$presInEnc<-presInEnc
# create list number
wideData$listN<-(as.numeric(substr(p, 5,6))%%4)+1
# compute percentage HIT
wideData$HITrate<-wideData$HIT/(wideData$HIT+wideData$Miss)
# percentage false alarm
wideData$FArate<-wideData$FA/(wideData$FA+wideData$CorrRej)
# calculate dprime
library(psycho)
indices <- psycho::dprime(wideData$HIT, wideData$FA, wideData$Miss, wideData$CorrRej)
wideData<-cbind(wideData, indices)
# PR
wideData$hitMinFA<-wideData$HITrate-wideData$FArate
# attach accuracy in the encoding file
encoding$recogAcc<-NA
for (n in 1:nrow(encoding)){
if (length(recog$acc[recog$images==encoding$img[n]])!=0){
encoding$recogAcc[n]<-recog$acc[recog$images==encoding$img[n]]
}
}
# check hit rate by condition
hitRbyCond<-encoding %>%
group_by(condition)%>%
dplyr::summarise(hitRCond= mean(recogAcc))
wideData$HITrateLearned<-hitRbyCond$hitRCond[1]
wideData$HITrateKnown<-hitRbyCond$hitRCond[2]
# attach to the datasets
longDatarecog<-rbind(longDatarecog, recog)
# create participant for the wide dataset
wideData$participant<-substr(p, 5,6)
recogData<-rbind(recogData, wideData)
#------------------------------------------------------------------------------#
#
# Analyze Data Expra
#
# created: "Wed Jan 19 19:18:16 2022"
#
# Francesco Pupillo, Goethe University Frankfurt
#
#------------------------------------------------------------------------------#
library(data.table)
library(dplyr)
rm(list=ls())
# puth the path with the data
inPath <- "..."
# clean data files
inPath<-"all_file_encoding"
# how many subjects?
subjects<-list.files(inPath)
# import the files
inFiles <- list.files(inPath, pattern="*.csv", full.names=TRUE)
data <- rbindlist(lapply(inFiles,fread),fill=TRUE)
getwd()
setwd("/home/francesco/PowerFolders/MemLear/2_Analysis_Folder/")
# clean data files
inPath<-"all_file_encoding"
# how many subjects?
subjects<-list.files(inPath)
# import the files
inFiles <- list.files(inPath, pattern="*.csv", full.names=TRUE)
data <- rbindlist(lapply(inFiles,fread),fill=TRUE)
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
View(data.agg)
View(data.agg)
# check hit rate by condition
hitRbyCond<-encoding %>%
group_by(condition)%>%
dplyr::summarise(hitRCond= mean(recogAcc))
# attach accuracy in the encoding file
encoding$recogAcc<-NA
for (n in 1:nrow(encoding)){
if (length(recog$acc[recog$images==encoding$img[n]])!=0){
encoding$recogAcc[n]<-recog$acc[recog$images==encoding$img[n]]
}
}
dataAgg %>%
group_by( condition) %>%
summarise(recogMean = mean(recogAcc, na.rm = T))
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
data.agg %>%
group_by( condition) %>%
summarise(recogMean = mean(recogAcc, na.rm = T))
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
data %>%
group_by( condition) %>%
summarise(recogMean = mean(recogAcc, na.rm = T))
library(lme4)
View(data)
# summarise, check distribution
model<-lmer(recogAcc~condition + (1| participant), family = binomial(), data = data)
# summarise, check distribution
model<-glmer(recogAcc~condition + (1| participant), family = binomial(), data = data)
# summarise, check distribution
model<-glmer(recogAcc~condition + (1+condition| participant), family = binomial(), data = data)
summary(model)
# select only the first ones
data %>%
group_by(participant) %>%
tally()
View(data)
data.filter <- data.agg %>%
filter(trialN<61)
data.filter <- data %>%
filter(trialN<61)
modelFilter<-glmer(recogAcc~condition + (1+condition| participant), family = binomial(), data = data.filter)
summary(modelFilter)
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
# exlcude participants due to problems with lists
part.list.exc<-c(12, 13, 21)
# threshold for excluding participants at encoding
thres.encoding<-0.50
# threshold for excluding participants at retrieval
thres.retrieval<-0.50
# in order to have overall perf, let's aggregate without condition
data.agg.all<- data %>%
group_by(participant) %>%
summarise(recog.acc = mean(recogAcc, na.rm=T),
encoding.acc = mean(task_response.corr))
# which participants to exclude according to encoding performance
part.exc.encod<-data.agg.all$participant[data.agg.all$encoding.acc<thres.encoding ]
# which participants to exclude according to retrieval performance
part.exc.retrieval<-data.agg.all$participant[data.agg.all$recog.acc<thres.retrieval ]
excl.all<-unique(c(part.list.exc, part.exc.encod,part.exc.retrieval ))
# exclude
excl.all<-excl.all[!excl.all$participants %in% partExcl, ]
# exclude
data.exlc<-data[!data$participants %in% excl.all, ]
# exclude
excl<-data[!data$participant %in% excl.all, ]
# with exclusion
modelexc<-glmer(recogAcc~condition + (1+condition| participant), family = binomial(), data = excl)
summary(modelexc)
#
data.excl.filter <- excl %>%
filter(trialN<61)
model.excl.Filter<-glmer(recogAcc~condition + (1+condition| participant), family = binomial(), data = data.excl.filter)
summary(model.excl.Filter)
#
data.excl.filter <- excl %>%
filter(trialN>61)
model.excl.Filter<-glmer(recogAcc~condition + (1+condition| participant), family = binomial(), data = data.excl.filter)
summary(model.excl.Filter)
# with exclusion
modelexc<-glmer(recogAcc~condition + (1+condition| participant), family = binomial(), data = excl)
summary(modelexc)
# summarise
data.exc.agg<-excl %>%
group_by( condition) %>%
summarise(recogMean = mean(recogAcc, na.rm = T))
View(data.exc.agg)
# summarise
data.exc.agg<-excl %>%
group_by( condition) %>%
summarise(recogMean = mean(recogAcc, na.rm = T))
library(ggplot2)
plot<-ggplot(data.exc.agg, aes(condition, recogMean, fill = recogMean))
plot+geom_boxplot()
data.exc.agg<-as.factor(data.exc.agg$condition)
data.exc.agg$condition<-as.factor(data.exc.agg$condition)
# summarise
data.exc.agg<-excl %>%
group_by( condition) %>%
summarise(recogMean = mean(recogAcc, na.rm = T))
data.exc.agg$condition<-as.factor(data.exc.agg$condition)
plot<-ggplot(data.exc.agg, aes(condition, recogMean, fill = recogMean))
plot+geom_boxplot()
plot<-ggplot(data.exc.agg, aes(x = condition, y = recogMean, fill = condition))
plot+geom_boxplot()
plot+  geom_bar(aes(PE, rec_acc, fill = PE),
position="dodge",stat="summary")
plot+  geom_bar(
position="dodge",stat="summary")
rm(list=ls())
# puth the path with the data
inPath <- "..."
# clean data files
inPath<-"all_file_encoding"
# how many subjects?
subjects<-list.files(inPath)
# import the files
inFiles <- list.files(inPath, pattern="*.csv", full.names=TRUE)
data <- rbindlist(lapply(inFiles,fread),fill=TRUE)
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
# exlcude participants due to problems with lists
part.list.exc<-c(12, 13, 21)
#------------------------------------------------------------------------------#
#
# Analyze Data Expra
#
# created: "Wed Jan 19 19:18:16 2022"
#
# Francesco Pupillo, Goethe University Frankfurt
#
#------------------------------------------------------------------------------#
library(data.table)
library(dplyr)
library(lme4)
library(ggplot2)
rm(list=ls())
# puth the path with the data
inPath <- "..."
# clean data files
inPath<-"all_file_encoding"
# how many subjects?
subjects<-list.files(inPath)
# import the files
inFiles <- list.files(inPath, pattern="*.csv", full.names=TRUE)
data <- rbindlist(lapply(inFiles,fread),fill=TRUE)
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
# exlcude participants due to problems with lists
part.list.exc<-c(12, 13, 21)
# import the files
inFiles <- list.files(inPath, pattern="*.csv", full.names=TRUE)
getwd()
setwd("2_Analysis_Folder")
# how many subjects?
subjects<-list.files(inPath)
# import the files
inFiles <- list.files(inPath, pattern="*.csv", full.names=TRUE)
data <- rbindlist(lapply(inFiles,fread),fill=TRUE)
data.agg<-data %>%
group_by(participant, condition) %>%
summarise(recog.acc = mean(recogAcc),
encoding.acc = mean(task_response.corr))
# exlcude participants due to problems with lists
part.list.exc<-c(12, 13, 21)
# threshold for excluding participants at encoding
thres.encoding<-0.50
# threshold for excluding participants at retrieval
thres.retrieval<-0.50
# in order to have overall perf, let's aggregate without condition
data.agg.all<- data %>%
group_by(participant) %>%
summarise(recog.acc = mean(recogAcc, na.rm=T),
encoding.acc = mean(task_response.corr))
# which participants to exclude according to encoding performance
part.exc.encod<-data.agg.all$participant[data.agg.all$encoding.acc<thres.encoding ]
# which participants to exclude according to retrieval performance
part.exc.retrieval<-data.agg.all$participant[data.agg.all$recog.acc<thres.retrieval ]
excl.all<-unique(c(part.list.exc, part.exc.encod,part.exc.retrieval ))
# exclude
excl<-data[!data$participant %in% excl.all, ]
data %>%
group_by( condition) %>%
summarise(recogMean = mean(recogAcc, na.rm = T))
# summarise, check distribution
model<-glmer(recogAcc~condition + (1+condition| participant), family = binomial(), data = data)
summary(model)
# with exclusion
modelexc<-glmer(recogAcc~condition + (1+condition| participant), family = binomial(), data = excl)
summary(modelexc)
1/6
